{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IPATokenizer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32Jj8mygiEws",
        "outputId": "9f1953bb-c58c-4d6f-d5b8-e98a5beb1d34"
      },
      "source": [
        "!pip install allosaurus\n",
        "!pip install tokenizers\n",
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting allosaurus\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/8c/64fc6fc14e527889d0ee18c2c1b2b109c48ae31e6683de7b60607e65cf17/allosaurus-0.5.2-py3-none-any.whl (51kB)\n",
            "\r\u001b[K     |██████▍                         | 10kB 14.7MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 20kB 14.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 30kB 9.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 40kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 51kB 5.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (from allosaurus) (0.5.3)\n",
            "Collecting panphon\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/6e/a6928ab77ef8adbc4929c9203471501901d10bdc1d7b2e689fb00b26cf77/panphon-0.19-py2.py3-none-any.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from allosaurus) (1.19.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from allosaurus) (1.8.1+cu101)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from allosaurus) (1.4.1)\n",
            "Requirement already satisfied: resampy in /usr/local/lib/python3.7/dist-packages (from allosaurus) (0.2.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from panphon->allosaurus) (2019.12.20)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from panphon->allosaurus) (56.0.0)\n",
            "Collecting munkres\n",
            "  Downloading https://files.pythonhosted.org/packages/90/ab/0301c945a704218bc9435f0e3c88884f6b19ef234d8899fb47ce1ccfd0c9/munkres-1.1.4-py2.py3-none-any.whl\n",
            "Collecting unicodecsv\n",
            "  Downloading https://files.pythonhosted.org/packages/6f/a4/691ab63b17505a26096608cc309960b5a6bdf39e4ba1a793d5f9b1a53270/unicodecsv-0.14.1.tar.gz\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from panphon->allosaurus) (3.13)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->allosaurus) (3.7.4.3)\n",
            "Requirement already satisfied: numba>=0.32 in /usr/local/lib/python3.7/dist-packages (from resampy->allosaurus) (0.51.2)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy->allosaurus) (1.15.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.32->resampy->allosaurus) (0.34.0)\n",
            "Building wheels for collected packages: unicodecsv\n",
            "  Building wheel for unicodecsv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unicodecsv: filename=unicodecsv-0.14.1-cp37-none-any.whl size=10768 sha256=e5fc16a09578537b97947fa4eb20ddb805ba6350163081c011b0cd738a70650d\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/09/e9/e800279c98a0a8c94543f3de6c8a562f60e51363ed26e71283\n",
            "Successfully built unicodecsv\n",
            "Installing collected packages: munkres, unicodecsv, panphon, allosaurus\n",
            "Successfully installed allosaurus-0.5.2 munkres-1.1.4 panphon-0.19 unicodecsv-0.14.1\n",
            "Collecting tokenizers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 6.7MB/s \n",
            "\u001b[?25hInstalling collected packages: tokenizers\n",
            "Successfully installed tokenizers-0.10.2\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 40.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.45 transformers-4.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RARQSfPcjUqs",
        "outputId": "602005ea-0d08-4817-b82a-5e205207e35c"
      },
      "source": [
        "!python -m allosaurus.bin.list_phone "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/allosaurus/bin/list_phone.py\", line 15, in <module>\n",
            "    model_path = get_model_path(args.model)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/allosaurus/model.py\", line 27, in get_model_path\n",
            "    resolved_model_name = resolve_model_name(model_name)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/allosaurus/model.py\", line 76, in resolve_model_name\n",
            "    return models[0].name\n",
            "IndexError: list index out of range\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUy6XgGFmP8T"
      },
      "source": [
        "import random\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import WordLevel\n",
        "from tokenizers.trainers import WordLevelTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6V2lbYgj5Zc"
      },
      "source": [
        "# copy from https://github.com/xinjli/allosaurus\n",
        "ipa0 = ['I', 'a', 'aː', 'ã', 'ă', 'b', 'bʲ', 'bʲj', 'bʷ', 'bʼ', 'bː', 'b̞', 'b̤', 'b̥', 'c', 'd', 'dʒ', 'dʲ', 'dː', 'd̚', 'd̥', 'd̪', 'd̯', 'd͡z', 'd͡ʑ', 'd͡ʒ', 'd͡ʒː', 'd͡ʒ̤', 'e', 'eː', 'e̞', 'f', 'fʲ', 'fʷ', 'fː', 'g', 'gʲ', 'gʲj', 'gʷ', 'gː', 'h', 'hʷ', 'i', 'ij', 'iː', 'i̞', 'i̥', 'i̯', 'j', 'k', 'kx', 'kʰ', 'kʲ', 'kʲj', 'kʷ', 'kʷʼ', 'kʼ', 'kː', 'k̟ʲ', 'k̟̚', 'k͡p̚', 'l', 'lʲ', 'lː', 'l̪', 'm', 'mʲ', 'mʲj', 'mʷ', 'mː', 'n', 'nj', 'nʲ', 'nː', 'n̪', 'n̺', 'o', 'oː', 'o̞', 'o̥', 'p', 'pf', 'pʰ', 'pʲ', 'pʲj', 'pʷ', 'pʷʼ', 'pʼ', 'pː', 'p̚', 'q', 'r', 'rː', 's', 'sʲ', 'sʼ', 'sː', 's̪', 't', 'ts', 'tsʰ', 'tɕ', 'tɕʰ', 'tʂ', 'tʂʰ', 'tʃ', 'tʰ', 'tʲ', 'tʷʼ', 'tʼ', 'tː', 't̚', 't̪', 't̪ʰ', 't̪̚', 't͡s', 't͡sʼ', 't͡ɕ', 't͡ɬ', 't͡ʃ', 't͡ʃʲ', 't͡ʃʼ', 't͡ʃː', 'u', 'uə', 'uː', 'u͡w', 'v', 'vʲ', 'vʷ', 'vː', 'v̞', 'v̞ʲ', 'w', 'x', 'x̟ʲ', 'y', 'z', 'zj', 'zʲ', 'z̪', 'ä', 'æ', 'ç', 'çj', 'ð', 'ø', 'ŋ', 'ŋ̟', 'ŋ͡m', 'œ', 'œ̃', 'ɐ', 'ɐ̞', 'ɑ', 'ɑ̱', 'ɒ', 'ɓ', 'ɔ', 'ɔ̃', 'ɕ', 'ɕː', 'ɖ̤', 'ɗ', 'ə', 'ɛ', 'ɛ̃', 'ɟ', 'ɡ', 'ɡʲ', 'ɡ̤', 'ɡ̥', 'ɣ', 'ɣj', 'ɤ', 'ɤɐ̞', 'ɤ̆', 'ɥ', 'ɦ', 'ɨ', 'ɪ', 'ɫ', 'ɯ', 'ɯ̟', 'ɯ̥', 'ɰ', 'ɱ', 'ɲ', 'ɳ', 'ɴ', 'ɵ', 'ɸ', 'ɹ', 'ɹ̩', 'ɻ', 'ɻ̩', 'ɽ', 'ɾ', 'ɾj', 'ɾʲ', 'ɾ̠', 'ʀ', 'ʁ', 'ʁ̝', 'ʂ', 'ʃ', 'ʃʲː', 'ʃ͡ɣ', 'ʈ', 'ʉ̞', 'ʊ', 'ʋ', 'ʋʲ', 'ʌ', 'ʎ', 'ʏ', 'ʐ', 'ʑ', 'ʒ', 'ʒ͡ɣ', 'ʔ', 'ʝ', 'ː', 'β', 'β̞', 'θ', 'χ', 'ә', 'ḁ']\n",
        "ipa1, ipa2, ipa3 = ipa0.copy(), ipa0.copy(), ipa0.copy()\n",
        "random.shuffle(ipa1)\n",
        "random.shuffle(ipa2)\n",
        "random.shuffle(ipa3)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezdVxXpInY7Q"
      },
      "source": [
        "# randomly joined to form training data\n",
        "passage0 = ' '.join(ipa0)\n",
        "passage1 = ' '.join(ipa1)\n",
        "passage2 = ' '.join(ipa2)\n",
        "passage3 = ' '.join(ipa3)\n",
        "data = [passage0, passage1, passage2, passage3]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mKf-G_XnTbH"
      },
      "source": [
        "# setup\n",
        "tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
        "trainer = WordLevelTrainer(vocab_size=300, special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])\n",
        "tokenizer.pre_tokenizer = Whitespace()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-fcXGmapJW1"
      },
      "source": [
        "# train the tokenizer\n",
        "tokenizer.train_from_iterator(data, trainer=trainer)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpLSVuR9pRDP",
        "outputId": "b13bfae5-fdd7-4ef9-9e09-c71a8d8209f9"
      },
      "source": [
        "print(tokenizer.encode(passage0).tokens == ipa0)\n",
        "print(tokenizer.get_vocab())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "{'nʲ': 143, 'ɕː': 153, 'ɣj': 81, 'bʲj': 114, 'ɽ': 161, 'eː': 202, 'e': 211, 'ʌ': 221, 'uː': 21, 'tː': 22, 'ʐ': 101, 'd͡ʑ': 229, 'nː': 105, 'ɓ': 117, 'k̟ʲ': 88, 't̪': 109, 'u͡w': 24, 'ɦ': 46, 'ʋ': 190, 't̪ʰ': 215, 'z': 48, '[CLS]': 1, 't͡ʃʲ': 144, 'kː': 175, 'i̯': 50, 'ɗ': 34, 'gʲ': 207, 'ɸ': 118, 'v̞ʲ': 91, 'h': 110, 'n̪': 44, 'dʒ': 86, 'ŋ̟': 199, 'ɴ': 7, 'd͡ʒ̤': 12, 'r': 203, 'dʲ': 231, 'ɻ': 210, 'ɡ̥': 145, 'ä': 111, 'l': 57, 'b̥': 85, 'u': 13, 'tʼ': 128, 'ɹ̩': 78, 's': 9, 'ɖ̤': 26, 'z̪': 39, 'ʃʲː': 228, 'ij': 5, 'pː': 121, 'tʂʰ': 165, 'ə': 226, 'ŋ͡m': 208, 'ɾ': 35, 'ɤɐ̞': 106, 'ø': 181, 'θ': 72, 'g': 159, 'pʼ': 157, 'ã': 51, 't͡ɬ': 225, 'tʰ': 233, 'o̞': 73, 'n̺': 99, 't': 173, 'ʃ': 186, 'ʒ': 20, 'dː': 200, 'pʷ': 217, 't̚': 103, 'tʂ': 16, 'o': 119, 'ә': 167, 'kʷʼ': 104, 'd': 41, '[SEP]': 2, '[MASK]': 4, 't͡sʼ': 227, 'd͡ʒ': 126, 't͡ʃʼ': 141, 'b̞': 59, 'd̪': 76, 'ɟ': 90, 'fʲ': 148, 'pf': 169, 'ɔ̃': 102, 'lʲ': 96, 'tʲ': 10, 'fː': 171, 't͡ɕ': 65, 'ʊ': 184, 'zj': 195, 'tʷʼ': 17, 'ɳ': 8, 'ɾj': 151, 'ʂ': 212, 'β': 38, 'tʃ': 223, 'ɰ': 11, 'x̟ʲ': 77, 'tsʰ': 166, 'd̚': 122, 'pʲ': 197, 'ɨ': 123, 'i': 37, 'e̞': 80, 'ɑ̱': 156, 'ʔ': 172, 'β̞': 232, 'ʈ': 95, 'vʷ': 193, 'd͡z': 224, 'ð': 97, 'iː': 116, 'ts': 82, 'ː': 194, '[PAD]': 3, 'gʲj': 31, 'bʲ': 113, 'ɔ': 52, 'ḁ': 23, 'aː': 69, 'ʃ͡ɣ': 98, 'ʑ': 133, 'ɯ': 204, 'ɐ̞': 132, 'kʰ': 74, 'pʷʼ': 71, 'c': 230, 'ʒ͡ɣ': 79, 'k': 176, 'mʲj': 220, 'bʷ': 158, 'ŋ': 6, 'çj': 134, 'uə': 19, 'ʁ̝': 205, 't͡ʃ': 120, 'a': 164, 'b': 40, 'b̤': 47, 'sʲ': 43, 'ɪ': 154, 'rː': 75, 'i̥': 191, 'j': 15, 'ɤ̆': 30, 'v̞': 36, 'zʲ': 146, 'ɫ': 32, 'bː': 14, 'm': 54, 'ɾʲ': 49, 'ɡ̤': 33, 'oː': 178, 'kʷ': 155, 'ɯ̟': 174, 'o̥': 45, 'p': 183, 't͡s': 25, 'pʲj': 87, 'k̟̚': 83, 'vː': 124, 'ɥ': 115, 'p̚': 198, 'œ': 56, 'vʲ': 150, 's̪': 68, 'sː': 213, '[UNK]': 0, 'sʼ': 170, 'ʉ̞': 189, 'kʲj': 112, 'tɕ': 27, 'æ': 142, 'k͡p̚': 55, 'χ': 58, 'w': 61, 'ɵ': 84, 'l̪': 136, 'x': 139, 'kʼ': 180, 'ɕ': 222, 'ʁ': 149, 'd͡ʒː': 185, 'I': 201, 'q': 130, 'ɯ̥': 168, 'ʀ': 196, 'f': 160, 'v': 67, 'ă': 177, 'ɡʲ': 93, 'n': 125, 'nj': 70, 'ɑ': 137, 'ʏ': 29, 'ɣ': 163, 'gː': 60, 't͡ʃː': 192, 'd̯': 138, 'ʎ': 147, 'gʷ': 219, 'kx': 94, 'œ̃': 179, 'ɹ': 131, 'ç': 218, 't̪̚': 66, 'ʋʲ': 129, 'mʲ': 89, 'y': 64, 'd̥': 100, 'ɱ': 28, 'mː': 152, 'lː': 206, 'bʼ': 18, 'ɐ': 92, 'kʲ': 188, 'ɾ̠': 209, 'ɡ': 42, 'tɕʰ': 214, 'pʰ': 107, 'ɤ': 63, 'ɲ': 135, 'ɛ̃': 182, 'i̞': 216, 'ɒ': 140, 'ɻ̩': 53, 'ɛ': 62, 'fʷ': 162, 'mʷ': 127, 'ʝ': 108, 'hʷ': 187}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgNp3bv6p7FZ"
      },
      "source": [
        "tokenizer.save('./ipa_tokenizer.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tonwqPvqqqKd"
      },
      "source": [
        "Load the tokenizer by calling\n",
        "tokenizer = Tokenizer.from_file(path_to_ipa_tokenizer)"
      ]
    }
  ]
}