{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "supreme-conditioning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import json\n",
    "import time\n",
    "from lscn import LSCNsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "radical-tennis",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_EN_X = \"../memory/enfr/en/train_x.npy\"\n",
    "TRAIN_EN_Y = \"../memory/enfr/en/train_y.npy\"\n",
    "VALID_EN_X = \"../memory/enfr/en/valid_x.npy\"\n",
    "VALID_EN_Y = \"../memory/enfr/en/valid_y.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "local-technology",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_phone_idx(file_path=\"../memory/enfr/en/phone_idx.json\"):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dedicated-light",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.load(TRAIN_EN_X, allow_pickle=True)\n",
    "train_y = np.load(TRAIN_EN_Y, allow_pickle=True)\n",
    "valid_x = np.load(VALID_EN_X, allow_pickle=True)\n",
    "valid_y = np.load(VALID_EN_Y, allow_pickle=True)\n",
    "phone2idx = load_phone_idx()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-excuse",
   "metadata": {},
   "source": [
    "### labels are [0, 1, 2, 3, 4, 5, 8], change 8 to 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "alternate-reliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y[train_y == 8] = len(np.unique(train_y)) - 1\n",
    "valid_y[valid_y == 8] = len(np.unique(valid_y)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "intellectual-underground",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "conscious-cancer",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhoneDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.length = len(Y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.Y[i]\n",
    "    \n",
    "    def collate_fn(batch):\n",
    "        batch_x = [torch.as_tensor(x) for x, y in batch]\n",
    "        batch_x_length = [len(x) for x in batch]\n",
    "        batch_x_padded = pad_sequence(batch_x, batch_first=True)\n",
    "        batch_y = torch.as_tensor([y for x, y in batch])\n",
    "        return batch_x_padded, batch_x_length, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "supreme-bradley",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_predictions = 0\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for batch_idx, (x_padded, x_lengths, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x_padded = x_padded.to(device)\n",
    "        target = target.to(device)\n",
    "        outputs = model(x_padded, x_lengths)\n",
    "        \n",
    "        loss = criterion(outputs, target)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_predictions += target.size(0)\n",
    "        correct_predictions += (predicted == target).sum().item()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    running_loss /= len(train_loader)\n",
    "    accuracy = (correct_predictions/total_predictions) * 100.0\n",
    "    print(\"Training loss: \", running_loss, \"Time: \", end_time - start_time, 's')\n",
    "    print(\"Training Accuracy\", accuracy, \"%\")\n",
    "    return running_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "noted-mercy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_epoch(model, valid_loader, criterion, device):\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        total_predictions = 0\n",
    "        correct_predictions = 0\n",
    "    \n",
    "        for batch_idx, (x_padded, x_lengths, target) in enumerate(train_loader):\n",
    "            x_padded = x_padded.to(device)\n",
    "            target = target.to(device)\n",
    "            outputs = model(x_padded, x_lengths)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_predictions += target.size(0)\n",
    "            correct_predictions += (predicted == target).sum().item()\n",
    "            loss = criterion(outputs, target).detach()\n",
    "            running_loss += loss.item()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    running_loss /= len(train_loader)\n",
    "    accuracy = (correct_predictions/total_predictions) * 100.0\n",
    "    print(\"Validation loss: \", running_loss, \"Time: \", end_time - start_time, 's')\n",
    "    print(\"Validation Accuracy\", accuracy, \"%\")\n",
    "    return running_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "boring-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PhoneDataset(train_x, train_y)\n",
    "valid_dataset = PhoneDataset(valid_x, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aboriginal-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=32, num_workers=8, collate_fn=PhoneDataset.collate_fn)\n",
    "valid_loader = DataLoader(valid_dataset, shuffle=False, batch_size=32, collate_fn=PhoneDataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "certified-treat",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size =  len(phone2idx)\n",
    "num_classes = len(np.unique(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "numerical-sullivan",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSCNsClassifier(vocab_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "frank-dance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSCNsClassifier(\n",
      "  (embed): Embedding(121, 128)\n",
      "  (convA): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (convB): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (lstm): LSTM(256, 128, batch_first=True)\n",
      "  (linear): Linear(in_features=128, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "miniature-carbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-dynamics",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    valid_loss, valid_acc = valid_epoch(model, valid_loader, criterion, device)\n",
    "    print(\"Epoch {} finished.\".format(epoch))\n",
    "    print('='*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-variable",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
