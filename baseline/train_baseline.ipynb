{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "supreme-conditioning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "# from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import json\n",
    "import time\n",
    "from lscn import LSCNsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "radical-tennis",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydir = \"../memory/cn/\"\n",
    "TRAIN_EN_X = mydir + \"train_x.npy\"\n",
    "TRAIN_EN_Y = mydir + \"train_y.npy\"\n",
    "VALID_EN_X = mydir + \"dev_x.npy\"\n",
    "VALID_EN_Y = mydir + \"dev_y.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "local-technology",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_phone_idx(file_path=\"../memory/cn/phone_idx.json\"):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dedicated-light",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.load(TRAIN_EN_X, allow_pickle=True)\n",
    "train_y = np.load(TRAIN_EN_Y, allow_pickle=True)\n",
    "valid_x = np.load(VALID_EN_X, allow_pickle=True)\n",
    "valid_y = np.load(VALID_EN_Y, allow_pickle=True)\n",
    "phone2idx = load_phone_idx()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-excuse",
   "metadata": {},
   "source": [
    "### labels in english dataset are [0, 1, 2, 3, 4, 5, 8], change 8 to 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "alternate-reliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_label = np.max(train_y)\n",
    "train_y[train_y == max_label] = len(np.unique(train_y)) - 1\n",
    "valid_y[valid_y == max_label] = len(np.unique(valid_y)) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "conscious-cancer",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhoneDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.length = len(Y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.Y[i]\n",
    "    \n",
    "    def collate_fn(batch):\n",
    "        batch_x = [torch.as_tensor(x) for x, y in batch]\n",
    "        batch_x_length = [len(x) for x in batch]\n",
    "        batch_x_padded = pad_sequence(batch_x, batch_first=True)\n",
    "        batch_y = torch.as_tensor([y for x, y in batch])\n",
    "        return batch_x_padded, batch_x_length, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "intellectual-underground",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abroad-luxembourg",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "supreme-bradley",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_predictions = 0\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for batch_idx, (x_padded, x_lengths, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x_padded = x_padded.to(device)\n",
    "        target = target.to(device)\n",
    "        outputs = model(x_padded, x_lengths)\n",
    "        \n",
    "        loss = criterion(outputs, target)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_predictions += target.size(0)\n",
    "        correct_predictions += (predicted == target).sum().item()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    running_loss /= len(train_loader)\n",
    "    accuracy = (correct_predictions/total_predictions) * 100.0\n",
    "    print(\"Training loss: \", running_loss, \"Time: \", end_time - start_time, 's')\n",
    "    print(\"Training Accuracy\", accuracy, \"%\")\n",
    "    return running_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "noted-mercy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_epoch(model, valid_loader, criterion, device):\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        total_predictions = 0\n",
    "        correct_predictions = 0\n",
    "    \n",
    "        for batch_idx, (x_padded, x_lengths, target) in enumerate(valid_loader):\n",
    "            x_padded = x_padded.to(device)\n",
    "            target = target.to(device)\n",
    "            outputs = model(x_padded, x_lengths)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_predictions += target.size(0)\n",
    "            correct_predictions += (predicted == target).sum().item()\n",
    "            loss = criterion(outputs, target).detach()\n",
    "            running_loss += loss.item()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    running_loss /= len(train_loader)\n",
    "    accuracy = (correct_predictions/total_predictions) * 100.0\n",
    "    print(\"Validation loss: \", running_loss, \"Time: \", end_time - start_time, 's')\n",
    "    print(\"Validation Accuracy\", accuracy, \"%\")\n",
    "    return running_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "boring-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PhoneDataset(train_x, train_y)\n",
    "valid_dataset = PhoneDataset(valid_x, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aboriginal-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=32, num_workers=8, collate_fn=PhoneDataset.collate_fn)\n",
    "valid_loader = DataLoader(valid_dataset, shuffle=False, batch_size=32, collate_fn=PhoneDataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "certified-treat",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size =  len(phone2idx)\n",
    "num_classes = len(np.unique(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "numerical-sullivan",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSCNsClassifier(vocab_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "frank-dance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSCNsClassifier(\n",
      "  (embed): Embedding(78, 128)\n",
      "  (convA): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (convB): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (lstm): LSTM(256, 128, batch_first=True)\n",
      "  (linear): Linear(in_features=128, out_features=9, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=5e-5)\n",
    "# scheduler = ReduceLROnPlateau(optimizer, factor=0.3, patience=2, verbose=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "miniature-carbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "democratic-dynamics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:  2.047017054251063 Time:  1.142214059829712 s\n",
      "Training Accuracy 42.0743998533993 %\n",
      "Validation loss:  0.44256327305620874 Time:  0.06317996978759766 s\n",
      "Validation Accuracy 43.28358208955223 %\n",
      "Epoch 1 finished.\n",
      "====================\n",
      "Training loss:  1.703428346511216 Time:  1.1075811386108398 s\n",
      "Training Accuracy 55.83654022356607 %\n",
      "Validation loss:  0.4039159574006733 Time:  0.06315422058105469 s\n",
      "Validation Accuracy 44.02985074626866 %\n",
      "Epoch 2 finished.\n",
      "====================\n",
      "Training loss:  1.444504806172778 Time:  1.1041550636291504 s\n",
      "Training Accuracy 56.367967747846805 %\n",
      "Validation loss:  0.39994065385115773 Time:  0.06264734268188477 s\n",
      "Validation Accuracy 43.946932006633496 %\n",
      "Epoch 3 finished.\n",
      "====================\n",
      "Training loss:  1.3455923028856691 Time:  1.1029331684112549 s\n",
      "Training Accuracy 56.44126809602346 %\n",
      "Validation loss:  0.4063758989523726 Time:  0.06260395050048828 s\n",
      "Validation Accuracy 43.946932006633496 %\n",
      "Epoch 4 finished.\n",
      "====================\n",
      "Training loss:  1.3120887798872607 Time:  1.0838441848754883 s\n",
      "Training Accuracy 56.44126809602346 %\n",
      "Validation loss:  0.41112714029892145 Time:  0.06299328804016113 s\n",
      "Validation Accuracy 43.946932006633496 %\n",
      "Epoch 5 finished.\n",
      "====================\n",
      "Training loss:  1.2969426495289942 Time:  1.1088597774505615 s\n",
      "Training Accuracy 56.44126809602346 %\n",
      "Validation loss:  0.41277836603030826 Time:  0.06301641464233398 s\n",
      "Validation Accuracy 43.946932006633496 %\n",
      "Epoch 6 finished.\n",
      "====================\n",
      "Training loss:  1.2889154361702546 Time:  1.1064643859863281 s\n",
      "Training Accuracy 56.47791827011178 %\n",
      "Validation loss:  0.4127892457950882 Time:  0.06298041343688965 s\n",
      "Validation Accuracy 43.946932006633496 %\n",
      "Epoch 7 finished.\n",
      "====================\n",
      "Training loss:  1.2812576579768755 Time:  1.0908174514770508 s\n",
      "Training Accuracy 56.47791827011178 %\n",
      "Validation loss:  0.4118266300848353 Time:  0.06275343894958496 s\n",
      "Validation Accuracy 43.946932006633496 %\n",
      "Epoch 8 finished.\n",
      "====================\n",
      "Training loss:  1.2757214537838049 Time:  1.1038539409637451 s\n",
      "Training Accuracy 56.47791827011178 %\n",
      "Validation loss:  0.4122597216165554 Time:  0.06313037872314453 s\n",
      "Validation Accuracy 43.946932006633496 %\n",
      "Epoch 9 finished.\n",
      "====================\n",
      "Training loss:  1.270686391849964 Time:  1.0940885543823242 s\n",
      "Training Accuracy 56.47791827011178 %\n",
      "Validation loss:  0.4118246565088194 Time:  0.0631711483001709 s\n",
      "Validation Accuracy 43.946932006633496 %\n",
      "Epoch 10 finished.\n",
      "====================\n",
      "Training loss:  1.2660134480013485 Time:  1.087636947631836 s\n",
      "Training Accuracy 56.47791827011178 %\n",
      "Validation loss:  0.41048806487468253 Time:  0.06266951560974121 s\n",
      "Validation Accuracy 43.946932006633496 %\n",
      "Epoch 11 finished.\n",
      "====================\n",
      "Training loss:  1.2621966422649853 Time:  1.0968544483184814 s\n",
      "Training Accuracy 56.53289353124428 %\n",
      "Validation loss:  0.41022860132462796 Time:  0.06287431716918945 s\n",
      "Validation Accuracy 44.69320066334992 %\n",
      "Epoch 12 finished.\n",
      "====================\n",
      "Training loss:  1.2593981411024842 Time:  1.1135847568511963 s\n",
      "Training Accuracy 57.30254718709914 %\n",
      "Validation loss:  0.4098267628435503 Time:  0.06317424774169922 s\n",
      "Validation Accuracy 45.107794361525706 %\n",
      "Epoch 13 finished.\n",
      "====================\n",
      "Training loss:  1.2546477373580487 Time:  1.1047899723052979 s\n",
      "Training Accuracy 57.57742349276159 %\n",
      "Validation loss:  0.4085627090164095 Time:  0.062470197677612305 s\n",
      "Validation Accuracy 45.107794361525706 %\n",
      "Epoch 14 finished.\n",
      "====================\n",
      "Training loss:  1.2505275133060434 Time:  1.0931472778320312 s\n",
      "Training Accuracy 57.50412314458494 %\n",
      "Validation loss:  0.40725326050094696 Time:  0.06272315979003906 s\n",
      "Validation Accuracy 44.776119402985074 %\n",
      "Epoch 15 finished.\n",
      "====================\n",
      "Training loss:  1.2482407556639776 Time:  1.0897467136383057 s\n",
      "Training Accuracy 57.55909840571742 %\n",
      "Validation loss:  0.40655613677543506 Time:  0.06306314468383789 s\n",
      "Validation Accuracy 44.776119402985074 %\n",
      "Epoch 16 finished.\n",
      "====================\n",
      "Training loss:  1.2442566149416026 Time:  1.0954844951629639 s\n",
      "Training Accuracy 57.44914788345245 %\n",
      "Validation loss:  0.40605272187127006 Time:  0.06304073333740234 s\n",
      "Validation Accuracy 44.776119402985074 %\n",
      "Epoch 17 finished.\n",
      "====================\n",
      "Training loss:  1.240916997717138 Time:  1.0828046798706055 s\n",
      "Training Accuracy 57.55909840571742 %\n",
      "Validation loss:  0.40420919203618816 Time:  0.06245160102844238 s\n",
      "Validation Accuracy 44.44444444444444 %\n",
      "Epoch 18 finished.\n",
      "====================\n",
      "Training loss:  1.237404039380146 Time:  1.1111831665039062 s\n",
      "Training Accuracy 57.57742349276159 %\n",
      "Validation loss:  0.4044445495159305 Time:  0.06283140182495117 s\n",
      "Validation Accuracy 44.44444444444444 %\n",
      "Epoch 19 finished.\n",
      "====================\n",
      "Training loss:  1.2335144636923807 Time:  1.112971544265747 s\n",
      "Training Accuracy 57.68737401502657 %\n",
      "Validation loss:  0.40305078726762916 Time:  0.06320714950561523 s\n",
      "Validation Accuracy 44.61028192371476 %\n",
      "Epoch 20 finished.\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    valid_loss, valid_acc = valid_epoch(model, valid_loader, criterion, device)\n",
    "#     scheduler.step(valid_loss)\n",
    "    print(\"Epoch {} finished.\".format(epoch))\n",
    "    print('='*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-variable",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
