Testing English dataset with Roberta

heads = 1
Evaluate on validation using the best model
F1 Macro: 0.4810806311455789, F1 Micro: 0.6321525885558583
Accuracy: 0.6321525885558583
              precision    recall  f1-score   support

           0       0.44      0.43      0.43        42
           1       0.29      0.30      0.29        33
           2       0.55      0.66      0.60        35
           3       0.47      0.45      0.46        38
           4       0.39      0.29      0.33        38
           5       0.38      0.31      0.34        26
           6       0.88      0.94      0.91       155

    accuracy                           0.63       367
   macro avg       0.49      0.48      0.48       367
weighted avg       0.62      0.63      0.62       367

Best validation accuracy:  63.21525885558583 %

heads = 6
Evaluate on validation using the best model
F1 Macro: 0.5075315511786874, F1 Micro: 0.6539509536784741
Accuracy: 0.6539509536784741
              precision    recall  f1-score   support

           0       0.43      0.50      0.46        42
           1       0.48      0.39      0.43        33
           2       0.50      0.60      0.55        35
           3       0.44      0.45      0.44        38
           4       0.34      0.29      0.31        38
           5       0.43      0.38      0.41        26
           6       0.95      0.95      0.95       155

    accuracy                           0.65       367
   macro avg       0.51      0.51      0.51       367
weighted avg       0.65      0.65      0.65       367

Best validation accuracy:  65.39509536784742 %

heads = 12
Evaluate on validation using the best model
F1 Macro: 0.48606918077984995, F1 Micro: 0.6403269754768393
Accuracy: 0.6403269754768393
              precision    recall  f1-score   support

           0       0.39      0.36      0.38        42
           1       0.47      0.42      0.44        33
           2       0.48      0.60      0.53        35
           3       0.41      0.39      0.40        38
           4       0.39      0.37      0.38        38
           5       0.36      0.31      0.33        26
           6       0.93      0.95      0.94       155

    accuracy                           0.64       367
   macro avg       0.49      0.49      0.49       367
weighted avg       0.63      0.64      0.63       367

Best validation accuracy:  64.03269754768392 %

heads = 24
Evaluate on validation using the best model
F1 Macro: 0.4855893949868552, F1 Micro: 0.6348773841961853
Accuracy: 0.6348773841961853
              precision    recall  f1-score   support

           0       0.38      0.38      0.38        42
           1       0.52      0.39      0.45        33
           2       0.49      0.51      0.50        35
           3       0.40      0.50      0.45        38
           4       0.34      0.34      0.34        38
           5       0.40      0.31      0.35        26
           6       0.92      0.94      0.93       155

    accuracy                           0.63       367
   macro avg       0.49      0.48      0.49       367
weighted avg       0.63      0.63      0.63       367

Best validation accuracy:  63.48773841961853 %



num_layers= 1
Evaluate on validation using the best model
F1 Macro: 0.4445216211417254, F1 Micro: 0.6185286103542235
Accuracy: 0.6185286103542235
              precision    recall  f1-score   support

           0       0.43      0.21      0.29        42
           1       0.36      0.48      0.42        33
           2       0.45      0.54      0.49        35
           3       0.33      0.45      0.38        38
           4       0.53      0.26      0.35        38
           5       0.30      0.23      0.26        26
           6       0.88      0.97      0.92       155

    accuracy                           0.62       367
   macro avg       0.47      0.45      0.44       367
weighted avg       0.61      0.62      0.60       367

Best validation accuracy:  61.85286103542234 %

num_layers= 3
Evaluate on validation using the best model
F1 Macro: 0.4524107966772587, F1 Micro: 0.6158038147138964
Accuracy: 0.6158038147138964
              precision    recall  f1-score   support

           0       0.31      0.36      0.33        42
           1       0.34      0.33      0.34        33
           2       0.47      0.51      0.49        35
           3       0.44      0.39      0.42        38
           4       0.40      0.21      0.28        38
           5       0.34      0.42      0.38        26
           6       0.91      0.95      0.93       155

    accuracy                           0.62       367
   macro avg       0.46      0.46      0.45       367
weighted avg       0.61      0.62      0.61       367

Best validation accuracy:  61.58038147138964 %

num_layers= 6
Evaluate on validation using the best model
F1 Macro: 0.48606918077984995, F1 Micro: 0.6403269754768393
Accuracy: 0.6403269754768393
              precision    recall  f1-score   support

           0       0.39      0.36      0.38        42
           1       0.47      0.42      0.44        33
           2       0.48      0.60      0.53        35
           3       0.41      0.39      0.40        38
           4       0.39      0.37      0.38        38
           5       0.36      0.31      0.33        26
           6       0.93      0.95      0.94       155

    accuracy                           0.64       367
   macro avg       0.49      0.49      0.49       367
weighted avg       0.63      0.64      0.63       367

Best validation accuracy:  64.03269754768392 %



Testing Chinese dataset with Roberta

heads = 1
Evaluate on validation using the best model
F1 Macro: 0.5332252959182161, F1 Micro: 0.6291698991466252
Accuracy: 0.6291698991466252
              precision    recall  f1-score   support

           0       0.73      0.80      0.76       665
           1       0.51      0.30      0.38       251
           2       0.43      0.36      0.39       162
           3       0.53      0.70      0.60       211

    accuracy                           0.63      1289
   macro avg       0.55      0.54      0.53      1289
weighted avg       0.62      0.63      0.61      1289

Best validation accuracy:  62.91698991466252 %

heads = 6
Evaluate on validation using the best model
F1 Macro: 0.5132491872043983, F1 Micro: 0.6268425135764158
Accuracy: 0.6268425135764158
              precision    recall  f1-score   support

           0       0.70      0.82      0.76       665
           1       0.53      0.24      0.33       251
           2       0.43      0.28      0.34       162
           3       0.55      0.73      0.62       211

    accuracy                           0.63      1289
   macro avg       0.55      0.52      0.51      1289
weighted avg       0.61      0.63      0.60      1289

Best validation accuracy:  62.684251357641585 %

heads = 12
Evaluate on validation using the best model
F1 Macro: 0.5072158415400656, F1 Micro: 0.6322730799069046
Accuracy: 0.6322730799069046
              precision    recall  f1-score   support

           0       0.68      0.87      0.76       665
           1       0.54      0.23      0.32       251
           2       0.42      0.27      0.33       162
           3       0.60      0.63      0.62       211

    accuracy                           0.63      1289
   macro avg       0.56      0.50      0.51      1289
weighted avg       0.61      0.63      0.60      1289

Best validation accuracy:  63.22730799069046 %

heads = 24
Evaluate on validation using the best model
F1 Macro: 0.5470126285747895, F1 Micro: 0.6431342125678821
Accuracy: 0.6431342125678821
              precision    recall  f1-score   support

           0       0.72      0.80      0.76       665
           1       0.46      0.51      0.49       251
           2       0.54      0.23      0.32       162
           3       0.63      0.61      0.62       211

    accuracy                           0.64      1289
   macro avg       0.59      0.54      0.55      1289
weighted avg       0.64      0.64      0.63      1289

Best validation accuracy:  64.3134212567882 %



num_layers= 1
Evaluate on validation using the best model
F1 Macro: 0.5033487785627331, F1 Micro: 0.6268425135764158
Accuracy: 0.6268425135764158
              precision    recall  f1-score   support

           0       0.68      0.85      0.76       665
           1       0.54      0.22      0.32       251
           2       0.43      0.27      0.33       162
           3       0.56      0.67      0.61       211

    accuracy                           0.63      1289
   macro avg       0.55      0.50      0.50      1289
weighted avg       0.60      0.63      0.59      1289

Best validation accuracy:  62.684251357641585 %

num_layers= 3
Evaluate on validation using the best model
F1 Macro: 0.5383033960984208, F1 Micro: 0.6384794414274632
Accuracy: 0.6384794414274632
              precision    recall  f1-score   support

           0       0.72      0.82      0.77       665
           1       0.41      0.49      0.45       251
           2       0.52      0.21      0.30       162
           3       0.71      0.58      0.64       211

    accuracy                           0.64      1289
   macro avg       0.59      0.52      0.54      1289
weighted avg       0.63      0.64      0.63      1289

Best validation accuracy:  63.847944142746314 %

num_layers= 6
Evaluate on validation using the best model
F1 Macro: 0.5072158415400656, F1 Micro: 0.6322730799069046
Accuracy: 0.6322730799069046
              precision    recall  f1-score   support

           0       0.68      0.87      0.76       665
           1       0.54      0.23      0.32       251
           2       0.42      0.27      0.33       162
           3       0.60      0.63      0.62       211

    accuracy                           0.63      1289
   macro avg       0.56      0.50      0.51      1289
weighted avg       0.61      0.63      0.60      1289

Best validation accuracy:  63.22730799069046 %



